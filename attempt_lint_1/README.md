# Transformer Model Implementation

This project provides a modular and extensible implementation of the Transformer model, as described in the paper "Attention Is All You Need" (Vaswani et al., 2017). It is designed for machine translation tasks but can be adapted for other sequence-to-sequence problems like parsing.

## Project Structure